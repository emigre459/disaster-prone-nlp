{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/DisasterTweets.db')\n",
    "df = pd.read_sql_table('categorized_messages', engine)\n",
    "features = df['message']\n",
    "labels = df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26216 entries, 0 to 26215\n",
      "Data columns (total 40 columns):\n",
      "id                        26216 non-null int64\n",
      "message                   26216 non-null object\n",
      "original                  10170 non-null object\n",
      "genre                     26216 non-null object\n",
      "related                   26216 non-null int64\n",
      "request                   26216 non-null int64\n",
      "offer                     26216 non-null int64\n",
      "aid_related               26216 non-null int64\n",
      "medical_help              26216 non-null int64\n",
      "medical_products          26216 non-null int64\n",
      "search_and_rescue         26216 non-null int64\n",
      "security                  26216 non-null int64\n",
      "military                  26216 non-null int64\n",
      "child_alone               26216 non-null int64\n",
      "water                     26216 non-null int64\n",
      "food                      26216 non-null int64\n",
      "shelter                   26216 non-null int64\n",
      "clothing                  26216 non-null int64\n",
      "money                     26216 non-null int64\n",
      "missing_people            26216 non-null int64\n",
      "refugees                  26216 non-null int64\n",
      "death                     26216 non-null int64\n",
      "other_aid                 26216 non-null int64\n",
      "infrastructure_related    26216 non-null int64\n",
      "transport                 26216 non-null int64\n",
      "buildings                 26216 non-null int64\n",
      "electricity               26216 non-null int64\n",
      "tools                     26216 non-null int64\n",
      "hospitals                 26216 non-null int64\n",
      "shops                     26216 non-null int64\n",
      "aid_centers               26216 non-null int64\n",
      "other_infrastructure      26216 non-null int64\n",
      "weather_related           26216 non-null int64\n",
      "floods                    26216 non-null int64\n",
      "storm                     26216 non-null int64\n",
      "fire                      26216 non-null int64\n",
      "earthquake                26216 non-null int64\n",
      "cold                      26216 non-null int64\n",
      "other_weather             26216 non-null int64\n",
      "direct_report             26216 non-null int64\n",
      "dtypes: int64(37), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weather update - a cold front from Cuba that could pass over Haiti'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I'm making lemmatization optional in the following function as I may want to use part-of-speech tagging and/or named entity recognition results as engineered features later, and lemmatization is likely to cause issues with those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lemma=True, use_spacy_full=False, use_spacy_lemma_only=True):\n",
    "    '''\n",
    "    Performs various preprocessing steps on a single piece of text. Specifically, this function:\n",
    "        1. Strips all leading and trailing whitespace\n",
    "        2. Makes everything lowercase\n",
    "        3. Removes punctuation\n",
    "        4. Tokenizes the text into individual words\n",
    "        5. Removes common English stopwords\n",
    "        6. If enabled, lemmatizes the remaining words\n",
    "        \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: string representing a single message\n",
    "    \n",
    "    lemma: bool. Indicates if lemmatization should be done\n",
    "    \n",
    "    use_spacy_full: bool. If True, performs a full corpus analysis (POS, lemmas of all types, etc.) \n",
    "        using the spacy package instead of nltk lemmatization\n",
    "        \n",
    "    use_spacy_lemma_only: bool. If True, only performs verb-based lemmatization. Faster than full spacy\n",
    "        corpus analysis by about 88x.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List of processed strings from a single message\n",
    "    '''\n",
    "    \n",
    "    # Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Make everything lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Retain only parts of text that are non-punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # Tokenize into individual words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove common English stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Lemmatize to root words, if option is enabled\n",
    "    if lemma and not use_spacy_full and not use_spacy_lemma_only:\n",
    "        words = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "    \n",
    "    elif lemma and use_spacy_full:\n",
    "        nlp = en_core_web_sm.load()\n",
    "        doc = nlp(text)\n",
    "        words = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        \n",
    "    elif lemma and use_spacy_lemma_only:        \n",
    "        from spacy.lemmatizer import Lemmatizer\n",
    "        from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "        lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "        words = [lemmatizer(w, u\"VERB\")[0] for w in words]\n",
    "        \n",
    "        \n",
    "    return  words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'report',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroy',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'function',\n",
       " 'need',\n",
       " 'supply',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(features.loc[3], use_spacy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now what happens if I use the spacy approach to lemmatization, wherein I don't have to specify a POS type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'report',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroy',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'functioning',\n",
       " 'need',\n",
       " 'supply',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(features.loc[3], use_spacy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It looks nltk and spacy lemmatization are effectively equivalent, so I'll just use spacy (since it doesn't limit itself just to nouns or verbs, for example)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tf-idf', TfidfVectorizer(tokenizer=tokenize)),\n",
    "    #('classifier', MultiOutputClassifier(GradientBoostingClassifier(), n_jobs=-1))\n",
    "    #('classifier', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    ('classifier', RandomForestClassifier())\n",
    "    ], \n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing tf-idf, total=84.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emigre459/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  11.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern=...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels,\n",
    "                                                                           test_size=0.2)\n",
    "\n",
    "# train the pipeline\n",
    "pipeline.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WHOA! The tf-idf step took almost an hour and a half?! That's not right.** I wonder if my lemmatization process is slowing things down? I know the raw sklearn tf-idf transformer is extremely efficient, so my custom tokenizer must be the problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.66 ms, sys: 3.63 ms, total: 10.3 ms\n",
      "Wall time: 68.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'report',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroy',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'function',\n",
       " 'need',\n",
       " 'supply',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenize(features.loc[3], use_spacy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now what happens if I use the spacy approach to lemmatization, wherein I don't have to specify a POS type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 227 ms, sys: 31.8 ms, total: 258 ms\n",
      "Wall time: 426 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'report',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroy',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'functioning',\n",
       " 'need',\n",
       " 'supply',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenize(features.loc[3], use_spacy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now we know that spacy is about 34x slower (looking at user time here, not wall time) than nltk for lemmatization for some reason (weird, because spacy is billed as being super efficient, but perhaps my approach to lemmatization with it is flawed).\n",
    "\n",
    "What if I don't even lemmatize anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.04 ms, sys: 2.35 ms, total: 7.39 ms\n",
      "Wall time: 51.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'reports',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroyed',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'functioning',\n",
       " 'needs',\n",
       " 'supplies',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenize(features.loc[3], lemma=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, not a dramatic improvement over nltk lemmatization, so I can probably keep the lemmatization step.\n",
    "\n",
    "Let's stop using single examples and see how fast nltk-alone lemmatization performs. I'll also look at what using the standard Lemmatizer object in spacy performs, instead of doing the full-blown corpus analysis approach I originally setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.71 ms ± 189 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tokenize(features.loc[3], use_spacy_full=False, use_spacy_lemma_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 ms ± 24.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tokenize(features.loc[3], use_spacy_full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.68 ms ± 164 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tokenize(features.loc[3], use_spacy_full=False, use_spacy_lemma_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alrighty there we go: our pipeline is now a lot more effective with the spacy non-full option (although still basically the same speed as nltk). Let's try that training again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tf-idf', TfidfVectorizer(tokenizer=tokenize)),\n",
    "    #('classifier', MultiOutputClassifier(GradientBoostingClassifier(), n_jobs=-1))\n",
    "    #('classifier', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    ('classifier', RandomForestClassifier())\n",
    "    ], \n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing tf-idf, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emigre459/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  13.5s\n",
      "CPU times: user 1min 28s, sys: 15 s, total: 1min 43s\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern=...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the pipeline - let's try that again\n",
    "pipeline.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YES. That did it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_pred = pipeline.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 370 ms, sys: 7.82 ms, total: 377 ms\n",
      "Wall time: 402 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reports = []\n",
    "\n",
    "for i, column in enumerate(labels_test.columns):\n",
    "    reports.append(pd.DataFrame.from_dict(classification_report(labels_test[column], labels_pred[:,i],\n",
    "                                                                labels=np.unique(labels_pred[:,i]),\n",
    "                                                                digits=2, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related\n",
      "\n",
      "                     0            1          2  accuracy    macro avg  \\\n",
      "precision     0.607767     0.853629   0.538462  0.803776     0.666619   \n",
      "recall        0.511020     0.898016   0.368421  0.803776     0.592486   \n",
      "f1-score      0.555211     0.875260   0.437500  0.803776     0.622657   \n",
      "support    1225.000000  3981.000000  38.000000  0.803776  5244.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.793912  \n",
      "recall         0.803776  \n",
      "f1-score       0.797324  \n",
      "support     5244.000000  \n",
      "\n",
      "\n",
      "\n",
      "Category: request\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.899028    0.798039  0.889207     0.848534      0.881985\n",
      "recall        0.976371    0.459887  0.889207     0.718129      0.889207\n",
      "f1-score      0.936105    0.583513  0.889207     0.759809      0.876600\n",
      "support    4359.000000  885.000000  0.889207  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: offer\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.996186     0.996186     0.996186      0.996186\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.998089     0.998089     0.998089      0.998089\n",
      "support    5224.000000  5224.000000  5224.000000   5224.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: aid_related\n",
      "\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.709801     0.772247  0.725591     0.741024      0.735534\n",
      "recall        0.902043     0.473855  0.725591     0.687949      0.725591\n",
      "f1-score      0.794458     0.587324  0.725591     0.690891      0.709100\n",
      "support    3083.000000  2161.000000  0.725591  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: medical_help\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.922297    0.631579  0.921243     0.776938      0.899124\n",
      "recall        0.998550    0.028708  0.921243     0.513629      0.921243\n",
      "f1-score      0.958910    0.054920  0.921243     0.506915      0.886852\n",
      "support    4826.000000  418.000000  0.921243  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: medical_products\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.950412    0.761905  0.949657     0.856158      0.940526\n",
      "recall        0.998994    0.058182  0.949657     0.528588      0.949657\n",
      "f1-score      0.974097    0.108108  0.949657     0.541103      0.928684\n",
      "support    4969.000000  275.000000  0.949657  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: search_and_rescue\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.973468    1.000000  0.973494     0.986734      0.974197\n",
      "recall        1.000000    0.034722  0.973494     0.517361      0.973494\n",
      "f1-score      0.986556    0.067114  0.973494     0.526835      0.961308\n",
      "support    5100.000000  144.000000  0.973494  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: security\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.983791     0.983791     0.983791      0.983791\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.991829     0.991829     0.991829      0.991829\n",
      "support    5159.000000  5159.000000  5159.000000   5159.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: military\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.963890    0.700000  0.963387     0.831945      0.954027\n",
      "recall        0.999406    0.035714  0.963387     0.517560      0.963387\n",
      "f1-score      0.981327    0.067961  0.963387     0.524644      0.947189\n",
      "support    5048.000000  196.000000  0.963387  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: child_alone\n",
      "\n",
      "                0  accuracy  macro avg  weighted avg\n",
      "precision     1.0       1.0        1.0           1.0\n",
      "recall        1.0       1.0        1.0           1.0\n",
      "f1-score      1.0       1.0        1.0           1.0\n",
      "support    5244.0       1.0     5244.0        5244.0\n",
      "\n",
      "\n",
      "\n",
      "Category: water\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.952510    0.882353  0.951373     0.917432      0.948229\n",
      "recall        0.997969    0.234375  0.951373     0.616172      0.951373\n",
      "f1-score      0.974710    0.370370  0.951373     0.672540      0.937832\n",
      "support    4924.000000  320.000000  0.951373  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: food\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.924723    0.785467  0.917048     0.855095      0.908789\n",
      "recall        0.986649    0.378333  0.917048     0.682491      0.917048\n",
      "f1-score      0.954683    0.510686  0.917048     0.732684      0.903882\n",
      "support    4644.000000  600.000000  0.917048  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: shelter\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.925292    0.846154  0.923722     0.885723      0.918169\n",
      "recall        0.996647    0.186441  0.923722     0.591544      0.923722\n",
      "f1-score      0.959645    0.305556  0.923722     0.632600      0.900772\n",
      "support    4772.000000  472.000000  0.923722  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: clothing\n",
      "\n",
      "                     0          1  accuracy    macro avg  weighted avg\n",
      "precision     0.985673   0.888889  0.985507     0.937281      0.984141\n",
      "recall        0.999806   0.096386  0.985507     0.548096      0.985507\n",
      "f1-score      0.992689   0.173913  0.985507     0.583301      0.979730\n",
      "support    5161.000000  83.000000  0.985507  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: money\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.978610    0.750000  0.978261     0.864305      0.973465\n",
      "recall        0.999610    0.050847  0.978261     0.525229      0.978261\n",
      "f1-score      0.988998    0.095238  0.978261     0.542118      0.968887\n",
      "support    5126.000000  118.000000  0.978261  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: missing_people\n",
      "\n",
      "                     0          1  accuracy    macro avg  weighted avg\n",
      "precision     0.987412   1.000000  0.987414     0.993706      0.987573\n",
      "recall        1.000000   0.014925  0.987414     0.507463      0.987414\n",
      "f1-score      0.993666   0.029412  0.987414     0.511539      0.981346\n",
      "support    5177.000000  67.000000  0.987414  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: refugees\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.964497    0.800000   0.96434     0.882249      0.958537\n",
      "recall        0.999802    0.021053   0.96434     0.510427      0.964340\n",
      "f1-score      0.981832    0.041026   0.96434     0.511429      0.947745\n",
      "support    5054.000000  190.000000   0.96434  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: death\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.956888    0.760000   0.95595     0.858444      0.947727\n",
      "recall        0.998800    0.077869   0.95595     0.538334      0.955950\n",
      "f1-score      0.977395    0.141264   0.95595     0.559329      0.938490\n",
      "support    5000.000000  244.000000   0.95595  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: other_aid\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.870062    0.487500  0.864226     0.678781      0.818266\n",
      "recall        0.990957    0.054930  0.864226     0.522943      0.864226\n",
      "f1-score      0.926583    0.098734  0.864226     0.512658      0.814498\n",
      "support    4534.000000  710.000000  0.864226  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: infrastructure_related\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.941423    0.333333  0.941076     0.637378      0.905708\n",
      "recall        0.999595    0.003247  0.941076     0.501421      0.941076\n",
      "f1-score      0.969637    0.006431  0.941076     0.488034      0.913065\n",
      "support    4936.000000  308.000000  0.941076  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: transport\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.952872    1.000000  0.952899     0.976436      0.955118\n",
      "recall        1.000000    0.012000  0.952899     0.506000      0.952899\n",
      "f1-score      0.975867    0.023715  0.952899     0.499791      0.930475\n",
      "support    4994.000000  250.000000  0.952899  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: buildings\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.954058    0.650000  0.952899     0.802029      0.939389\n",
      "recall        0.998597    0.051383  0.952899     0.524990      0.952899\n",
      "f1-score      0.975820    0.095238  0.952899     0.535529      0.933336\n",
      "support    4991.000000  253.000000  0.952899  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: electricity\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.979592    1.000000  0.979596     0.989796      0.980012\n",
      "recall        1.000000    0.009259  0.979596     0.504630      0.979596\n",
      "f1-score      0.989691    0.018349  0.979596     0.504020      0.969686\n",
      "support    5136.000000  108.000000  0.979596  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: tools\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.994470     0.994470     0.994470      0.994470\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.997227     0.997227     0.997227      0.997227\n",
      "support    5215.000000  5215.000000  5215.000000   5215.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: hospitals\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.991800     0.991800     0.991800      0.991800\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.995883     0.995883     0.995883      0.995883\n",
      "support    5201.000000  5201.000000  5201.000000   5201.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: shops\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.996949     0.996949     0.996949      0.996949\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.998472     0.998472     0.998472      0.998472\n",
      "support    5228.000000  5228.000000  5228.000000   5228.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: aid_centers\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.989321     0.989321     0.989321      0.989321\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.994632     0.994632     0.994632      0.994632\n",
      "support    5188.000000  5188.000000  5188.000000   5188.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: other_infrastructure\n",
      "\n",
      "                     0      1  accuracy    macro avg  weighted avg\n",
      "precision     0.958604    0.0  0.958238     0.479302      0.918936\n",
      "recall        0.999602    0.0  0.958238     0.499801      0.958238\n",
      "f1-score      0.978674    0.0  0.958238     0.489337      0.938176\n",
      "support    5027.000000  217.0  0.958238  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: weather_related\n",
      "\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.841961     0.863326  0.845538     0.852643      0.847860\n",
      "recall        0.968388     0.523481  0.845538     0.745934      0.845538\n",
      "f1-score      0.900760     0.651763  0.845538     0.776261      0.832005\n",
      "support    3796.000000  1448.000000  0.845538  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: floods\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.936986    0.925373   0.93669     0.931180      0.935999\n",
      "recall        0.997916    0.278027   0.93669     0.637971      0.936690\n",
      "f1-score      0.966492    0.427586   0.93669     0.697039      0.920658\n",
      "support    4798.000000  446.000000   0.93669  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: storm\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.932977    0.801075  0.928299     0.867026      0.920703\n",
      "recall        0.992220    0.305328  0.928299     0.648774      0.928299\n",
      "f1-score      0.961687    0.442136  0.928299     0.701912      0.913339\n",
      "support    4756.000000  488.000000  0.928299  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: fire\n",
      "\n",
      "                     0     1  accuracy    macro avg  weighted avg\n",
      "precision     0.990082   0.0  0.989893     0.495041      0.980264\n",
      "recall        0.999807   0.0  0.989893     0.499904      0.989893\n",
      "f1-score      0.994921   0.0  0.989893     0.497460      0.985055\n",
      "support    5192.000000  52.0  0.989893  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: earthquake\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.953150    0.866438  0.948322     0.909794      0.945131\n",
      "recall        0.991805    0.521649  0.948322     0.756727      0.948322\n",
      "f1-score      0.972094    0.651223  0.948322     0.811658      0.942417\n",
      "support    4759.000000  485.000000  0.948322  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: cold\n",
      "\n",
      "                     0          1  accuracy    macro avg  weighted avg\n",
      "precision     0.983012   0.600000  0.982647     0.791506      0.976293\n",
      "recall        0.999612   0.032609  0.982647     0.516110      0.982647\n",
      "f1-score      0.991242   0.061856  0.982647     0.526549      0.974937\n",
      "support    5152.000000  92.000000  0.982647  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: other_weather\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.949503    0.687500  0.948703     0.818501      0.935763\n",
      "recall        0.998994    0.040000  0.948703     0.519497      0.948703\n",
      "f1-score      0.973620    0.075601  0.948703     0.524611      0.926527\n",
      "support    4969.000000  275.000000  0.948703  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: direct_report\n",
      "\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.858392     0.766968  0.850686     0.812680      0.840627\n",
      "recall        0.975621     0.332679  0.850686     0.654150      0.850686\n",
      "f1-score      0.913260     0.464066  0.850686     0.688663      0.825974\n",
      "support    4225.000000  1019.000000  0.850686  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, report in enumerate(reports):\n",
    "    print(f\"Category: {labels.columns[i]}\\n\")\n",
    "    print(report)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the mean weighted average f1-score look like across categories? This is roughly the best metric I can think of for measuring overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_weighted_f1_score(reports):\n",
    "    '''\n",
    "    Extracts the weighted average precision and recall scores from each category that the model predicted,\n",
    "    takes the harmonic mean of each metric, and then applies them in the f1 formula. \n",
    "    Meant to be used as an overall model performance measure.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    reports: list of pandas DataFrames, where each DataFrame is the result of a single message\n",
    "        category's classification_report resulting from test set prediction.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Overall model f1-score as a float.\n",
    "    '''\n",
    "    \n",
    "    mean_precision = pd.Series([report.loc['precision', 'weighted avg'] for report in reports]).mean()\n",
    "    mean_recall = pd.Series([report.loc['recall', 'weighted avg'] for report in reports]).mean()\n",
    "    \n",
    "    return stats.hmean([mean_precision, mean_recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392606772981869"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weighted_f1_score(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's not half bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = \n",
    "\n",
    "cv = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DisasterNLP]",
   "language": "python",
   "name": "conda-env-DisasterNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
