{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/DisasterTweets.db')\n",
    "df = pd.read_sql_table('categorized_messages', engine)\n",
    "features = df['message']\n",
    "labels = df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26215 entries, 0 to 26214\n",
      "Data columns (total 40 columns):\n",
      "id                        26215 non-null int64\n",
      "message                   26215 non-null object\n",
      "original                  10170 non-null object\n",
      "genre                     26215 non-null object\n",
      "related                   26215 non-null int64\n",
      "request                   26215 non-null int64\n",
      "offer                     26215 non-null int64\n",
      "aid_related               26215 non-null int64\n",
      "medical_help              26215 non-null int64\n",
      "medical_products          26215 non-null int64\n",
      "search_and_rescue         26215 non-null int64\n",
      "security                  26215 non-null int64\n",
      "military                  26215 non-null int64\n",
      "child_alone               26215 non-null int64\n",
      "water                     26215 non-null int64\n",
      "food                      26215 non-null int64\n",
      "shelter                   26215 non-null int64\n",
      "clothing                  26215 non-null int64\n",
      "money                     26215 non-null int64\n",
      "missing_people            26215 non-null int64\n",
      "refugees                  26215 non-null int64\n",
      "death                     26215 non-null int64\n",
      "other_aid                 26215 non-null int64\n",
      "infrastructure_related    26215 non-null int64\n",
      "transport                 26215 non-null int64\n",
      "buildings                 26215 non-null int64\n",
      "electricity               26215 non-null int64\n",
      "tools                     26215 non-null int64\n",
      "hospitals                 26215 non-null int64\n",
      "shops                     26215 non-null int64\n",
      "aid_centers               26215 non-null int64\n",
      "other_infrastructure      26215 non-null int64\n",
      "weather_related           26215 non-null int64\n",
      "floods                    26215 non-null int64\n",
      "storm                     26215 non-null int64\n",
      "fire                      26215 non-null int64\n",
      "earthquake                26215 non-null int64\n",
      "cold                      26215 non-null int64\n",
      "other_weather             26215 non-null int64\n",
      "direct_report             26215 non-null int64\n",
      "dtypes: int64(37), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20093\n",
       "0     6122\n",
       "Name: related, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the right classes, 0 and 1, are present\n",
    "df['related'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weather update - a cold front from Cuba that could pass over Haiti'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I'm making lemmatization optional in the following function as I may want to use part-of-speech tagging and/or named entity recognition results as engineered features later, and lemmatization is likely to cause issues with those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lemma=True, use_spacy_full=False, use_spacy_lemma_only=True):\n",
    "    '''\n",
    "    Performs various preprocessing steps on a single piece of text. Specifically, this function:\n",
    "        1. Strips all leading and trailing whitespace\n",
    "        2. Makes everything lowercase\n",
    "        3. Removes punctuation\n",
    "        4. Tokenizes the text into individual words\n",
    "        5. Removes common English stopwords\n",
    "        6. If enabled, lemmatizes the remaining words\n",
    "        \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: string representing a single message\n",
    "    \n",
    "    lemma: bool. Indicates if lemmatization should be done\n",
    "    \n",
    "    use_spacy_full: bool. If True, performs a full corpus analysis (POS, lemmas of all types, etc.) \n",
    "        using the spacy package instead of nltk lemmatization\n",
    "        \n",
    "    use_spacy_lemma_only: bool. If True, only performs verb-based lemmatization. Faster than full spacy\n",
    "        corpus analysis by about 88x.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List of processed strings from a single message\n",
    "    '''\n",
    "    \n",
    "    # Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Make everything lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Retain only parts of text that are non-punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # Tokenize into individual words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove common English stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Lemmatize to root words, if option is enabled\n",
    "    if lemma and not use_spacy_full and not use_spacy_lemma_only:\n",
    "        words = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "    \n",
    "    elif lemma and use_spacy_full:\n",
    "        nlp = en_core_web_sm.load()\n",
    "        doc = nlp(text)\n",
    "        words = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        \n",
    "    elif lemma and use_spacy_lemma_only:        \n",
    "        from spacy.lemmatizer import Lemmatizer\n",
    "        from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "        lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "        words = [lemmatizer(w, u\"VERB\")[0] for w in words]\n",
    "        \n",
    "        \n",
    "    return  words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46 ms ± 497 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tokenize(features.loc[3], use_spacy_full=False, use_spacy_lemma_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now what happens if I use the spacy approach to lemmatization, wherein I don't have to specify a POS type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 ms ± 23.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tokenize(features.loc[3], use_spacy_full=True, use_spacy_lemma_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.72 ms ± 244 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tokenize(features.loc[3], use_spacy_full=False, use_spacy_lemma_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like spacy (lemmatization on verbs only) is a little faster than nltk, so let's go with that. ...and definitely don't use `spacy_full` for anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tf-idf', TfidfVectorizer(tokenizer=tokenize)),\n",
    "    #('classifier', MultiOutputClassifier(GradientBoostingClassifier(), n_jobs=-1))\n",
    "    #('classifier', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    ('classifier', RandomForestClassifier())\n",
    "    ], \n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into testing and training\n",
    "features_train, features_test, \n",
    "labels_train, labels_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the pipeline\n",
    "pipeline.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YES. That did it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "labels_pred = pipeline.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(classification_report(labels_test, labels_pred,\n",
    "                                             digits=2, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 370 ms, sys: 7.82 ms, total: 377 ms\n",
      "Wall time: 402 ms\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "\n",
    "for i, column in enumerate(labels_test.columns):\n",
    "    reports.append(pd.DataFrame.from_dict(classification_report(labels_test[column], labels_pred[:,i],\n",
    "                                                                labels=np.unique(labels_pred[:,i]),\n",
    "                                                                digits=2, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related\n",
      "\n",
      "                     0            1          2  accuracy    macro avg  \\\n",
      "precision     0.607767     0.853629   0.538462  0.803776     0.666619   \n",
      "recall        0.511020     0.898016   0.368421  0.803776     0.592486   \n",
      "f1-score      0.555211     0.875260   0.437500  0.803776     0.622657   \n",
      "support    1225.000000  3981.000000  38.000000  0.803776  5244.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.793912  \n",
      "recall         0.803776  \n",
      "f1-score       0.797324  \n",
      "support     5244.000000  \n",
      "\n",
      "\n",
      "\n",
      "Category: request\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.899028    0.798039  0.889207     0.848534      0.881985\n",
      "recall        0.976371    0.459887  0.889207     0.718129      0.889207\n",
      "f1-score      0.936105    0.583513  0.889207     0.759809      0.876600\n",
      "support    4359.000000  885.000000  0.889207  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: offer\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.996186     0.996186     0.996186      0.996186\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.998089     0.998089     0.998089      0.998089\n",
      "support    5224.000000  5224.000000  5224.000000   5224.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: aid_related\n",
      "\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.709801     0.772247  0.725591     0.741024      0.735534\n",
      "recall        0.902043     0.473855  0.725591     0.687949      0.725591\n",
      "f1-score      0.794458     0.587324  0.725591     0.690891      0.709100\n",
      "support    3083.000000  2161.000000  0.725591  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: medical_help\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.922297    0.631579  0.921243     0.776938      0.899124\n",
      "recall        0.998550    0.028708  0.921243     0.513629      0.921243\n",
      "f1-score      0.958910    0.054920  0.921243     0.506915      0.886852\n",
      "support    4826.000000  418.000000  0.921243  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: medical_products\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.950412    0.761905  0.949657     0.856158      0.940526\n",
      "recall        0.998994    0.058182  0.949657     0.528588      0.949657\n",
      "f1-score      0.974097    0.108108  0.949657     0.541103      0.928684\n",
      "support    4969.000000  275.000000  0.949657  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: search_and_rescue\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.973468    1.000000  0.973494     0.986734      0.974197\n",
      "recall        1.000000    0.034722  0.973494     0.517361      0.973494\n",
      "f1-score      0.986556    0.067114  0.973494     0.526835      0.961308\n",
      "support    5100.000000  144.000000  0.973494  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: security\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.983791     0.983791     0.983791      0.983791\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.991829     0.991829     0.991829      0.991829\n",
      "support    5159.000000  5159.000000  5159.000000   5159.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: military\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.963890    0.700000  0.963387     0.831945      0.954027\n",
      "recall        0.999406    0.035714  0.963387     0.517560      0.963387\n",
      "f1-score      0.981327    0.067961  0.963387     0.524644      0.947189\n",
      "support    5048.000000  196.000000  0.963387  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: child_alone\n",
      "\n",
      "                0  accuracy  macro avg  weighted avg\n",
      "precision     1.0       1.0        1.0           1.0\n",
      "recall        1.0       1.0        1.0           1.0\n",
      "f1-score      1.0       1.0        1.0           1.0\n",
      "support    5244.0       1.0     5244.0        5244.0\n",
      "\n",
      "\n",
      "\n",
      "Category: water\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.952510    0.882353  0.951373     0.917432      0.948229\n",
      "recall        0.997969    0.234375  0.951373     0.616172      0.951373\n",
      "f1-score      0.974710    0.370370  0.951373     0.672540      0.937832\n",
      "support    4924.000000  320.000000  0.951373  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: food\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.924723    0.785467  0.917048     0.855095      0.908789\n",
      "recall        0.986649    0.378333  0.917048     0.682491      0.917048\n",
      "f1-score      0.954683    0.510686  0.917048     0.732684      0.903882\n",
      "support    4644.000000  600.000000  0.917048  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: shelter\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.925292    0.846154  0.923722     0.885723      0.918169\n",
      "recall        0.996647    0.186441  0.923722     0.591544      0.923722\n",
      "f1-score      0.959645    0.305556  0.923722     0.632600      0.900772\n",
      "support    4772.000000  472.000000  0.923722  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: clothing\n",
      "\n",
      "                     0          1  accuracy    macro avg  weighted avg\n",
      "precision     0.985673   0.888889  0.985507     0.937281      0.984141\n",
      "recall        0.999806   0.096386  0.985507     0.548096      0.985507\n",
      "f1-score      0.992689   0.173913  0.985507     0.583301      0.979730\n",
      "support    5161.000000  83.000000  0.985507  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: money\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.978610    0.750000  0.978261     0.864305      0.973465\n",
      "recall        0.999610    0.050847  0.978261     0.525229      0.978261\n",
      "f1-score      0.988998    0.095238  0.978261     0.542118      0.968887\n",
      "support    5126.000000  118.000000  0.978261  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: missing_people\n",
      "\n",
      "                     0          1  accuracy    macro avg  weighted avg\n",
      "precision     0.987412   1.000000  0.987414     0.993706      0.987573\n",
      "recall        1.000000   0.014925  0.987414     0.507463      0.987414\n",
      "f1-score      0.993666   0.029412  0.987414     0.511539      0.981346\n",
      "support    5177.000000  67.000000  0.987414  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: refugees\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.964497    0.800000   0.96434     0.882249      0.958537\n",
      "recall        0.999802    0.021053   0.96434     0.510427      0.964340\n",
      "f1-score      0.981832    0.041026   0.96434     0.511429      0.947745\n",
      "support    5054.000000  190.000000   0.96434  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: death\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.956888    0.760000   0.95595     0.858444      0.947727\n",
      "recall        0.998800    0.077869   0.95595     0.538334      0.955950\n",
      "f1-score      0.977395    0.141264   0.95595     0.559329      0.938490\n",
      "support    5000.000000  244.000000   0.95595  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: other_aid\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.870062    0.487500  0.864226     0.678781      0.818266\n",
      "recall        0.990957    0.054930  0.864226     0.522943      0.864226\n",
      "f1-score      0.926583    0.098734  0.864226     0.512658      0.814498\n",
      "support    4534.000000  710.000000  0.864226  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: infrastructure_related\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.941423    0.333333  0.941076     0.637378      0.905708\n",
      "recall        0.999595    0.003247  0.941076     0.501421      0.941076\n",
      "f1-score      0.969637    0.006431  0.941076     0.488034      0.913065\n",
      "support    4936.000000  308.000000  0.941076  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: transport\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.952872    1.000000  0.952899     0.976436      0.955118\n",
      "recall        1.000000    0.012000  0.952899     0.506000      0.952899\n",
      "f1-score      0.975867    0.023715  0.952899     0.499791      0.930475\n",
      "support    4994.000000  250.000000  0.952899  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: buildings\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.954058    0.650000  0.952899     0.802029      0.939389\n",
      "recall        0.998597    0.051383  0.952899     0.524990      0.952899\n",
      "f1-score      0.975820    0.095238  0.952899     0.535529      0.933336\n",
      "support    4991.000000  253.000000  0.952899  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: electricity\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.979592    1.000000  0.979596     0.989796      0.980012\n",
      "recall        1.000000    0.009259  0.979596     0.504630      0.979596\n",
      "f1-score      0.989691    0.018349  0.979596     0.504020      0.969686\n",
      "support    5136.000000  108.000000  0.979596  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: tools\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.994470     0.994470     0.994470      0.994470\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.997227     0.997227     0.997227      0.997227\n",
      "support    5215.000000  5215.000000  5215.000000   5215.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: hospitals\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.991800     0.991800     0.991800      0.991800\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.995883     0.995883     0.995883      0.995883\n",
      "support    5201.000000  5201.000000  5201.000000   5201.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: shops\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.996949     0.996949     0.996949      0.996949\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.998472     0.998472     0.998472      0.998472\n",
      "support    5228.000000  5228.000000  5228.000000   5228.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: aid_centers\n",
      "\n",
      "                     0    micro avg    macro avg  weighted avg\n",
      "precision     0.989321     0.989321     0.989321      0.989321\n",
      "recall        1.000000     1.000000     1.000000      1.000000\n",
      "f1-score      0.994632     0.994632     0.994632      0.994632\n",
      "support    5188.000000  5188.000000  5188.000000   5188.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: other_infrastructure\n",
      "\n",
      "                     0      1  accuracy    macro avg  weighted avg\n",
      "precision     0.958604    0.0  0.958238     0.479302      0.918936\n",
      "recall        0.999602    0.0  0.958238     0.499801      0.958238\n",
      "f1-score      0.978674    0.0  0.958238     0.489337      0.938176\n",
      "support    5027.000000  217.0  0.958238  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: weather_related\n",
      "\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.841961     0.863326  0.845538     0.852643      0.847860\n",
      "recall        0.968388     0.523481  0.845538     0.745934      0.845538\n",
      "f1-score      0.900760     0.651763  0.845538     0.776261      0.832005\n",
      "support    3796.000000  1448.000000  0.845538  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: floods\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.936986    0.925373   0.93669     0.931180      0.935999\n",
      "recall        0.997916    0.278027   0.93669     0.637971      0.936690\n",
      "f1-score      0.966492    0.427586   0.93669     0.697039      0.920658\n",
      "support    4798.000000  446.000000   0.93669  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: storm\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.932977    0.801075  0.928299     0.867026      0.920703\n",
      "recall        0.992220    0.305328  0.928299     0.648774      0.928299\n",
      "f1-score      0.961687    0.442136  0.928299     0.701912      0.913339\n",
      "support    4756.000000  488.000000  0.928299  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: fire\n",
      "\n",
      "                     0     1  accuracy    macro avg  weighted avg\n",
      "precision     0.990082   0.0  0.989893     0.495041      0.980264\n",
      "recall        0.999807   0.0  0.989893     0.499904      0.989893\n",
      "f1-score      0.994921   0.0  0.989893     0.497460      0.985055\n",
      "support    5192.000000  52.0  0.989893  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: earthquake\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.953150    0.866438  0.948322     0.909794      0.945131\n",
      "recall        0.991805    0.521649  0.948322     0.756727      0.948322\n",
      "f1-score      0.972094    0.651223  0.948322     0.811658      0.942417\n",
      "support    4759.000000  485.000000  0.948322  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: cold\n",
      "\n",
      "                     0          1  accuracy    macro avg  weighted avg\n",
      "precision     0.983012   0.600000  0.982647     0.791506      0.976293\n",
      "recall        0.999612   0.032609  0.982647     0.516110      0.982647\n",
      "f1-score      0.991242   0.061856  0.982647     0.526549      0.974937\n",
      "support    5152.000000  92.000000  0.982647  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: other_weather\n",
      "\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.949503    0.687500  0.948703     0.818501      0.935763\n",
      "recall        0.998994    0.040000  0.948703     0.519497      0.948703\n",
      "f1-score      0.973620    0.075601  0.948703     0.524611      0.926527\n",
      "support    4969.000000  275.000000  0.948703  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n",
      "Category: direct_report\n",
      "\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.858392     0.766968  0.850686     0.812680      0.840627\n",
      "recall        0.975621     0.332679  0.850686     0.654150      0.850686\n",
      "f1-score      0.913260     0.464066  0.850686     0.688663      0.825974\n",
      "support    4225.000000  1019.000000  0.850686  5244.000000   5244.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, report in enumerate(reports):\n",
    "    print(f\"Category: {labels.columns[i]}\\n\")\n",
    "    print(report)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the mean weighted average f1-score look like across categories? This is roughly the best metric I can think of for measuring overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_weighted_f1_score(reports, average_type='macro avg'):\n",
    "    '''\n",
    "    Extracts the weighted average precision and recall scores from each category that the model predicted,\n",
    "    takes the harmonic mean of each metric, and then applies them in the f1 formula. \n",
    "    Meant to be used as an overall model performance measure.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    reports: list of pandas DataFrames, where each DataFrame is the result of a single message\n",
    "        category's classification_report resulting from test set prediction.\n",
    "        \n",
    "    average_type: str. Indicates which type of f1-score average you want to extract and\n",
    "        use for overall model performance evaluation. 'macro avg' is recommended as it properly\n",
    "        penalizes \n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Overall model f1-score as a float.\n",
    "    '''\n",
    "    \n",
    "    mean_precision = pd.Series([report.loc['precision', 'weighted avg'] for report in reports]).mean()\n",
    "    mean_recall = pd.Series([report.loc['recall', 'weighted avg'] for report in reports]).mean()\n",
    "    \n",
    "    return stats.hmean([mean_precision, mean_recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392606772981869"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weighted_f1_score(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's not half bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing tf-idf, total= 1.1min\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  39.7s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass-multioutput and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \"\"\"\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 97\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DisasterNLP/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'tf-idf__max_df': [0.1, 0.5, 0.9],\n",
    "    'classifier__n_estimators': [10,50,100,500],\n",
    "    'classifier__max_depth': [5,10, None],\n",
    "    'classifier__min_samples_split': [2, 4, 8],\n",
    "    'classifier__min_samples_leaf': [1, 6, 10]\n",
    "}\n",
    "\n",
    "cv = RandomizedSearchCV(pipeline, parameters, n_iter = 10, cv = 5, scoring='f1_weighted')\n",
    "cv.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DisasterNLP]",
   "language": "python",
   "name": "conda-env-DisasterNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
